{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1318e1c2",
   "metadata": {},
   "source": [
    "# Create validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feda7625",
   "metadata": {},
   "source": [
    "This script creates a fixed-size validation dataset of discharge notes for a heart failure cohort \n",
    "extracted from MIMIC-IV. It samples patients, extracts structured note sections (Chief Complaint, \n",
    "HPI, Physical Exam), and stores the processed data in JSON for downstream manual annotation and LLM evaluation.\n",
    "\n",
    "Workflow:\n",
    "---------\n",
    "1. Connects to PostgreSQL (MIMIC-IV) and selects 50 random patients with ICD-10 codes for heart failure.\n",
    "2. Selects 50 discharge notes (one per admission).\n",
    "3. Extracts key sections from each note using regex (Chief Complaint, HPI, Physical Exam).\n",
    "4. Prepares a structured JSON with placeholders for model outputs.\n",
    "5. Later updates the file to ensure full note text is included (for CC extraction).\n",
    "\n",
    "Output:\n",
    "-------\n",
    "- 'groud_truth.json' – initial structured note fragments + metadata.\n",
    "- 'groud_truth_and_full_notes.json' – updated with full note text and re-parsed CC for completeness.\n",
    "\n",
    "PD: The plan was to make this reproductible but the notes sent by postgres are different each time  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae7c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Install dependecies and conect to PostgreSQL database ===\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import json\n",
    "DB_NAME = \"mimic\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"sd98hS&GD3F4\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "\n",
    "engine = create_engine(f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ed4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# === Get the heart failure cohort and select 50 random patients ===\n",
    "def get_cohort(icd_code):\n",
    "    query = text('''\n",
    "    SELECT DISTINCT subject_id\n",
    "    FROM mimiciv_hosp.diagnoses_icd\n",
    "    WHERE icd_code_v2 LIKE :icd_code\n",
    "    ORDER BY subject_id;\n",
    "    ''')               \n",
    "    return pd.read_sql(query, engine, params={\"icd_code\": icd_code})\n",
    "\n",
    "cohort = get_cohort(\"I50%\") \n",
    "sampled_subjects = cohort.sample(n=50, random_state = 42) # 42 = fixed seed for reproducibility\n",
    "print(sampled_subjects.size)\n",
    "subject_ids = sampled_subjects['subject_id'].tolist()\n",
    "\n",
    "# === Get the admissions with notes for the sampled patients and select 50 random admissions ===\n",
    "query = text('''\n",
    "SELECT hadm_id\n",
    "FROM mimiciv_note.discharge\n",
    "WHERE subject_id = ANY(:subject_ids)\n",
    "''')\n",
    "admissions = pd.read_sql(query, engine, params={\"subject_ids\": subject_ids})\n",
    "sampled_admissions = admissions.sample(n=50, random_state = 42)\n",
    "print(sampled_admissions.size)\n",
    "hadm_ids = sampled_admissions['hadm_id'].tolist()\n",
    "\n",
    "# === Get the notes for the sampled admissions ===\n",
    "query = text('''\n",
    "SELECT ROW_NUMBER() OVER (ORDER BY hadm_id, charttime) AS note_number,\n",
    "    note_id, subject_id, hadm_id, charttime, text\n",
    "FROM mimiciv_note.discharge\n",
    "WHERE text IS NOT NULL\n",
    "  AND hadm_id = ANY(:hadm_ids)\n",
    "''')\n",
    "notes = pd.read_sql(query, engine, params={\"hadm_ids\": hadm_ids})\n",
    "print(notes[\"text\"].size)\n",
    "\n",
    "# print(notes[\"text\"][0])\n",
    "# print(notes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a241c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Extract Chief Complaint, Past Medical History and Physical Exam sections ===\n",
    "def extract_sections(note):\n",
    "    \n",
    "    # === Define the pattern to match the desired section ===  \n",
    "    sections = {\n",
    "        \"Chief Complaint\": [\n",
    "            (\"Chief Complaint:\", \"Major Surgical or Invasive Procedure:\"),\n",
    "            (\"___ Complaint:\", \"Major Surgical or Invasive Procedure:\")\n",
    "        ],\n",
    "        \"History of Present Illness\": [\n",
    "            (\"History of Present Illness:\", \"Past Medical History:\"),\n",
    "            (\"___ Present Illness:\", \"Past Medical History:\")\n",
    "        ],\n",
    "        \"Physical Exam\": [\n",
    "            (\"Physical Exam:\", \"Pertinent Results:\"),\n",
    "            (\"Physical ___:\", \"Pertinent Results:\"),\n",
    "            (\"Physical Exam:\", \"Brief Hospital Course:\")\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    extracted_sections = {}\n",
    "    for section_name, marker_pairs in sections.items():\n",
    "        found = False\n",
    "        for start_marker, end_marker in marker_pairs:\n",
    "            if start_marker in note and end_marker in note:\n",
    "                pattern = re.escape(start_marker) + r\"\\s*(.*?)\\s*\" + re.escape(end_marker)\n",
    "                match = re.search(pattern, note, re.DOTALL)\n",
    "                if match:\n",
    "                    extracted_sections[section_name] = match.group(1).strip()\n",
    "                    found = True\n",
    "                    break\n",
    "        if not found:\n",
    "            extracted_sections[section_name] = \"Section not found.\"\n",
    "    return extracted_sections\n",
    "\n",
    "# === Define the template ===\n",
    "def create_note_template(row):\n",
    "    return {\n",
    "        \"note_number\": int(row[\"note_number\"]),\n",
    "        \"note_id\": str(row[\"note_id\"]),\n",
    "        \"subject_id\": int(row[\"subject_id\"]),\n",
    "        \"hadm_id\": int(row[\"hadm_id\"]),\n",
    "        \"text\": row[\"text\"],\n",
    "        \"note_fragment\": str(row[\"note_fragment\"]),\n",
    "        \"chief_complaint\": str(row[\"chief_complaint\"]),\n",
    "        \"extracted_data\": {\n",
    "            \"Emergency Department\": {\n",
    "                \"Body Temperature\": None,\n",
    "                \"Systolic Blood Pressure\": None,\n",
    "                \"Diastolic Blood Pressure\": None,\n",
    "                \"Heart Rate\": None,\n",
    "                \"Respiratory Rate\": None,\n",
    "                \"Oxygen Saturation\": None\n",
    "            },\n",
    "            \"Admission\": {\n",
    "                \"Body Temperature\": None,\n",
    "                \"Systolic Blood Pressure\": None,\n",
    "                \"Diastolic Blood Pressure\": None,\n",
    "                \"Heart Rate\": None,\n",
    "                \"Respiratory Rate\": None,\n",
    "                \"Oxygen Saturation\": None\n",
    "            },\n",
    "            \"Transfer\": {\n",
    "                \"Body Temperature\": None,\n",
    "                \"Systolic Blood Pressure\": None,\n",
    "                \"Diastolic Blood Pressure\": None,\n",
    "                \"Heart Rate\": None,\n",
    "                \"Respiratory Rate\": None,\n",
    "                \"Oxygen Saturation\": None\n",
    "            },\n",
    "            \"Discharge\": {\n",
    "                \"Body Temperature\": None,\n",
    "                \"Systolic Blood Pressure\": None,\n",
    "                \"Diastolic Blood Pressure\": None,\n",
    "                \"Heart Rate\": None,\n",
    "                \"Respiratory Rate\": None,\n",
    "                \"Oxygen Saturation\": None\n",
    "            },\n",
    "            \"Unknown\": {\n",
    "                \"Body Temperature\": None,\n",
    "                \"Systolic Blood Pressure\": None,\n",
    "                \"Diastolic Blood Pressure\": None,\n",
    "                \"Heart Rate\": None,\n",
    "                \"Respiratory Rate\": None,\n",
    "                \"Oxygen Saturation\": None\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63dc200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Parse the notes ===\n",
    "sampled_notes = notes\n",
    "\n",
    "for index, row in notes.iterrows():\n",
    "\n",
    "    sections = extract_sections(row[\"text\"])\n",
    "    cc = sections[\"Chief Complaint\"]\n",
    "    hpi = sections[\"History of Present Illness\"]\n",
    "    pe = sections[\"Physical Exam\"]\n",
    "\n",
    "    note_fragment = f\"History of Present Illness:\\n{hpi}\\n\\n---------------------------\\n\\nPhysical Exam:\\n{pe}\"\n",
    "    sampled_notes.loc[index, \"note_fragment\"] = note_fragment\n",
    "    sampled_notes.loc[index, \"chief_complaint\"] = cc\n",
    "\n",
    "# print(notes.loc[0, \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70252a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save everything to JSON file ===\n",
    "\n",
    "json_data = [create_note_template(row) for _, row in sampled_notes.iterrows()]\n",
    "\n",
    "with open(\"ground_truth.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17097b30",
   "metadata": {},
   "source": [
    "At first I forgot to add the full notes (to extract cc), so I added them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafde570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Connect to the database ===\n",
    "DB_NAME = \"mimic\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"sd98hS&GD3F4\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "engine = create_engine(f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "\n",
    "# === Read the contents of the Ground Truth file ===\n",
    "with open(\"groud_truth.json\", 'r') as file:\n",
    "    validation_data = json.load(file)\n",
    "\n",
    "updated_data = []\n",
    "\n",
    "for row in validation_data:\n",
    "    \n",
    "    new_record = OrderedDict()\n",
    "    \n",
    "    note_id = row[\"note_id\"]\n",
    "\n",
    "    query = text('''\n",
    "    SELECT text\n",
    "    FROM mimiciv_note.discharge\n",
    "    WHERE note_id = :note_id\n",
    "    ''')\n",
    "    note = pd.read_sql(query, engine, params={\"note_id\": note_id})\n",
    "    note  = note[\"text\"].values[0]      \n",
    "\n",
    "    sections = extract_sections(note)\n",
    "    cc = sections[\"Chief Complaint\"]\n",
    "    hpi = sections[\"History of Present Illness\"]\n",
    "    pe = sections[\"Physical Exam\"]\n",
    "    note_fragment = f\"History of Present Illness:\\n{hpi}\\n\\n---------------------------\\n\\nPhysical Exam:\\n{pe}\"\n",
    "\n",
    "    for key, value in row.items():\n",
    "        new_record[key] = value\n",
    "        \n",
    "        if key == \"text\":\n",
    "            new_record[\"text\"] = note\n",
    "            new_record[\"note_fragment\"] = note_fragment\n",
    "\n",
    "    new_record[\"chief_complaint\"] = cc\n",
    "\n",
    "    updated_data.append(new_record)\n",
    "\n",
    "# === Save the updated list back to file ===\n",
    "with open(\"ground_truth_and_full_notes.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(updated_data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
